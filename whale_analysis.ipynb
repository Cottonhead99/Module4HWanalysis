{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #  A Whale off the Port(folio)\n",
    " ---\n",
    "\n",
    " In this assignment, you'll get to use what you've learned this week to evaluate the performance among various algorithmic, hedge, and mutual fund portfolios and compare them against the S&P 500 Index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x000001BF68B30B90>\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "%matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "In this section, you will need to read the CSV files into DataFrames and perform any necessary data cleaning steps. After cleaning, combine all DataFrames into a single DataFrame.\n",
    "\n",
    "Files:\n",
    "\n",
    "* `whale_returns.csv`: Contains returns of some famous \"whale\" investors' portfolios.\n",
    "\n",
    "* `algo_returns.csv`: Contains returns from the in-house trading algorithms from Harold's company.\n",
    "\n",
    "* `sp500_history.csv`: Contains historical closing prices of the S&P 500 Index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whale Returns\n",
    "\n",
    "Read the Whale Portfolio daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>SOROS FUND MANAGEMENT LLC</th>\n",
       "      <th>PAULSON &amp; CO.INC.</th>\n",
       "      <th>TIGER GLOBAL MANAGEMENT LLC</th>\n",
       "      <th>BERKSHIRE HATHAWAY INC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-03-03</td>\n",
       "      <td>-0.001266</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>-0.006569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>0.003241</td>\n",
       "      <td>-0.002534</td>\n",
       "      <td>0.004213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-03-05</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.006726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-06</td>\n",
       "      <td>-0.007905</td>\n",
       "      <td>-0.003574</td>\n",
       "      <td>-0.008481</td>\n",
       "      <td>-0.013098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  SOROS FUND MANAGEMENT LLC  PAULSON & CO.INC.   \\\n",
       "0  2015-03-02                        NaN                 NaN   \n",
       "1  2015-03-03                  -0.001266           -0.004981   \n",
       "2  2015-03-04                   0.002230            0.003241   \n",
       "3  2015-03-05                   0.004016            0.004076   \n",
       "4  2015-03-06                  -0.007905           -0.003574   \n",
       "\n",
       "   TIGER GLOBAL MANAGEMENT LLC  BERKSHIRE HATHAWAY INC  \n",
       "0                          NaN                     NaN  \n",
       "1                    -0.000496               -0.006569  \n",
       "2                    -0.002534                0.004213  \n",
       "3                     0.002355                0.006726  \n",
       "4                    -0.008481               -0.013098  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading whale returns\n",
    "Whales_returns_df = pd.read_csv ('Resources\\whale_returns.csv')\n",
    "Whales_returns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                           0\n",
       "SOROS FUND MANAGEMENT LLC      1\n",
       "PAULSON & CO.INC.              1\n",
       "TIGER GLOBAL MANAGEMENT LLC    1\n",
       "BERKSHIRE HATHAWAY INC         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count nulls\n",
    "Whales_returns_df.isnull()\n",
    "Whales_returns_df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "Whales_returns_df = Whales_returns_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithmic Daily Returns\n",
    "\n",
    "Read the algorithmic daily returns and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Algo 1</th>\n",
       "      <th>Algo 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-05-28</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-05-29</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-05-30</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-06-02</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-06-03</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date    Algo 1  Algo 2\n",
       "0  2014-05-28  0.001745     NaN\n",
       "1  2014-05-29  0.003978     NaN\n",
       "2  2014-05-30  0.004464     NaN\n",
       "3  2014-06-02  0.005692     NaN\n",
       "4  2014-06-03  0.005292     NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading algorithmic returns\n",
    "Algo_returns_df = pd.read_csv ('Resources\\\\algo_returns.csv')\n",
    "Algo_returns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date      0\n",
       "Algo 1    0\n",
       "Algo 2    6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count nulls\n",
    "Algo_returns_df.isnull()\n",
    "Algo_returns_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "Algo_returns_df = Algo_returns_df.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S&P 500 Returns\n",
    "\n",
    "Read the S&P 500 historic closing prices and create a new daily returns DataFrame from the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23-Apr-19</td>\n",
       "      <td>$2933.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22-Apr-19</td>\n",
       "      <td>$2907.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18-Apr-19</td>\n",
       "      <td>$2905.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17-Apr-19</td>\n",
       "      <td>$2900.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-Apr-19</td>\n",
       "      <td>$2907.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     Close\n",
       "0  23-Apr-19  $2933.68\n",
       "1  22-Apr-19  $2907.97\n",
       "2  18-Apr-19  $2905.03\n",
       "3  17-Apr-19  $2900.45\n",
       "4  16-Apr-19  $2907.06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading S&P 500 Closing Prices\n",
    "Sp500_historical_df = pd.read_csv('Resources\\\\sp500_history.csv')\n",
    "Sp500_historical_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date     object\n",
       "Close    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Data Types\n",
    "Sp500_historical_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix Data Types\n",
    "# set colum names\n",
    "column_names = [\"date\", \"close\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "\n",
    "\n",
    "\n",
    "# recreate the dataframe\n",
    "Sp500_historical_df = pd.read_csv('Resources\\\\sp500_history.csv', names= column_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrjwi\\AppData\\Local\\Temp\\ipykernel_52072\\4095058263.py:4: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Call ffill before calling pct_change to retain current behavior and silence this warning.\n",
      "  Sp500_historical_df = Sp500_historical_df.ffill().pct_change()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:220\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    221\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:131\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     result \u001b[39m=\u001b[39m _evaluate_standard(op, op_str, a, b)\n\u001b[0;32m    133\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'NoneType'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ricefolder\\RICE-VIRT-FIN-PT-08-2023-U-LOLC\\UntitledRepo\\Homework\\04-Pandas\\Instructions\\Starter_Code\\whale_analysis.ipynb Cell 16\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m daily_return \u001b[39m=\u001b[39m Path(\u001b[39m'\u001b[39m\u001b[39mResources\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39msp500_history.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m Sp500_historical_df[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(Sp500_historical_df[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm-\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m'\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m Sp500_historical_df \u001b[39m=\u001b[39m Sp500_historical_df\u001b[39m.\u001b[39;49mffill()\u001b[39m.\u001b[39;49mpct_change()\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11722\u001b[0m, in \u001b[0;36mNDFrame.pct_change\u001b[1;34m(self, periods, fill_method, limit, freq, **kwargs)\u001b[0m\n\u001b[0;32m  11720\u001b[0m shifted \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mshift(periods\u001b[39m=\u001b[39mperiods, freq\u001b[39m=\u001b[39mfreq, axis\u001b[39m=\u001b[39maxis, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m  11721\u001b[0m \u001b[39m# Unsupported left operand type for / (\"Self\")\u001b[39;00m\n\u001b[1;32m> 11722\u001b[0m rs \u001b[39m=\u001b[39m data \u001b[39m/\u001b[39;49m shifted \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m  11723\u001b[0m \u001b[39mif\u001b[39;00m freq \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m  11724\u001b[0m     \u001b[39m# Shift method is implemented differently when freq is not None\u001b[39;00m\n\u001b[0;32m  11725\u001b[0m     \u001b[39m# We want to restore the original index\u001b[39;00m\n\u001b[0;32m  11726\u001b[0m     rs \u001b[39m=\u001b[39m rs\u001b[39m.\u001b[39mloc[\u001b[39m~\u001b[39mrs\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mduplicated()]\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:210\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__truediv__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__truediv__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 210\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, operator\u001b[39m.\u001b[39;49mtruediv)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:7647\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7644\u001b[0m \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_align_for_op(other, axis, flex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, level\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   7646\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 7647\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch_frame_op(other, op, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   7648\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:7690\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[1;34m(self, right, func, axis)\u001b[0m\n\u001b[0;32m   7684\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mequals(right\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m   7685\u001b[0m     \u001b[39m# TODO: The previous assertion `assert right._indexed_same(self)`\u001b[39;00m\n\u001b[0;32m   7686\u001b[0m     \u001b[39m#  fails in cases with empty columns reached via\u001b[39;00m\n\u001b[0;32m   7687\u001b[0m     \u001b[39m#  _frame_arith_method_with_reindex\u001b[39;00m\n\u001b[0;32m   7688\u001b[0m \n\u001b[0;32m   7689\u001b[0m     \u001b[39m# TODO operate_blockwise expects a manager of the same type\u001b[39;00m\n\u001b[1;32m-> 7690\u001b[0m     bm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49moperate_blockwise(\n\u001b[0;32m   7691\u001b[0m         \u001b[39m# error: Argument 1 to \"operate_blockwise\" of \"ArrayManager\" has\u001b[39;49;00m\n\u001b[0;32m   7692\u001b[0m         \u001b[39m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   7693\u001b[0m         \u001b[39m# \"ArrayManager\"\u001b[39;49;00m\n\u001b[0;32m   7694\u001b[0m         \u001b[39m# error: Argument 1 to \"operate_blockwise\" of \"BlockManager\" has\u001b[39;49;00m\n\u001b[0;32m   7695\u001b[0m         \u001b[39m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   7696\u001b[0m         \u001b[39m# \"BlockManager\"\u001b[39;49;00m\n\u001b[0;32m   7697\u001b[0m         right\u001b[39m.\u001b[39;49m_mgr,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7698\u001b[0m         array_op,\n\u001b[0;32m   7699\u001b[0m     )\n\u001b[0;32m   7700\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(bm, axes\u001b[39m=\u001b[39mbm\u001b[39m.\u001b[39maxes)\n\u001b[0;32m   7702\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(right, Series) \u001b[39mand\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   7703\u001b[0m     \u001b[39m# axis=1 means we want to operate row-by-row\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1470\u001b[0m, in \u001b[0;36mBlockManager.operate_blockwise\u001b[1;34m(self, other, array_op)\u001b[0m\n\u001b[0;32m   1466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moperate_blockwise\u001b[39m(\u001b[39mself\u001b[39m, other: BlockManager, array_op) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BlockManager:\n\u001b[0;32m   1467\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1468\u001b[0m \u001b[39m    Apply array_op blockwise with another (aligned) BlockManager.\u001b[39;00m\n\u001b[0;32m   1469\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1470\u001b[0m     \u001b[39mreturn\u001b[39;00m operate_blockwise(\u001b[39mself\u001b[39;49m, other, array_op)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\ops.py:65\u001b[0m, in \u001b[0;36moperate_blockwise\u001b[1;34m(left, right, array_op)\u001b[0m\n\u001b[0;32m     63\u001b[0m res_blks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m lvals, rvals, locs, left_ea, right_ea, rblk \u001b[39min\u001b[39;00m _iter_block_pairs(left, right):\n\u001b[1;32m---> 65\u001b[0m     res_values \u001b[39m=\u001b[39m array_op(lvals, rvals)\n\u001b[0;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m     67\u001b[0m         left_ea\n\u001b[0;32m     68\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m right_ea\n\u001b[0;32m     69\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(res_values, \u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_1d_only_ea_dtype(res_values\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m     71\u001b[0m     ):\n\u001b[0;32m     72\u001b[0m         res_values \u001b[39m=\u001b[39m res_values\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:285\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    281\u001b[0m     _bool_arith_check(op, left, right)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[39m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:229\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    223\u001b[0m         left\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mgetattr\u001b[39m(right, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m\n\u001b[0;32m    224\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    228\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m         result \u001b[39m=\u001b[39m _masked_arith_op(left, right, op)\n\u001b[0;32m    230\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:165\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m--> 165\u001b[0m         result[mask] \u001b[39m=\u001b[39m op(xrav[mask], yrav[mask])\n\u001b[0;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# Calculate Daily Returns\n",
    "daily_return = Path('Resources\\\\sp500_history.csv')\n",
    "Sp500_historical_df['date'] = pd.to_datetime(Sp500_historical_df['date'], format='%d-%m-%Y', errors='coerce')\n",
    "Sp500_historical_df = Sp500_historical_df.ffill().pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sp500_historical_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ricefolder\\RICE-VIRT-FIN-PT-08-2023-U-LOLC\\UntitledRepo\\Homework\\04-Pandas\\Instructions\\Starter_Code\\whale_analysis.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Drop nulls\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Sp500_historical_df \u001b[39m=\u001b[39m Sp500_historical_df\u001b[39m.\u001b[39mdropna()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sp500_historical_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Drop nulls\n",
    "Sp500_historical_df = Sp500_historical_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename `Close` Column to be specific to this portfolio.\n",
    "Sp500_historical_df.rename(columns={'close': 'Portfolio_Close'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Whale, Algorithmic, and S&P 500 Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ricefolder\\RICE-VIRT-FIN-PT-08-2023-U-LOLC\\UntitledRepo\\Homework\\04-Pandas\\Instructions\\Starter_Code\\whale_analysis.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Join Whale Returns, Algorithmic Returns, and the S&P 500 Returns into a single DataFrame with columns for each portfolio's returns.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m column_appended_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([Sp500_historical_df, Algo_returns_df, Whales_returns_df], axis\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m, join\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m column_appended_data\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Join Whale Returns, Algorithmic Returns, and the S&P 500 Returns into a single DataFrame with columns for each portfolio's returns.\n",
    "column_appended_data = pd.concat([Sp500_historical_df, Algo_returns_df, Whales_returns_df], axis=\"columns\", join=\"inner\")\n",
    "column_appended_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conduct Quantitative Analysis\n",
    "\n",
    "In this section, you will calculate and visualize performance and risk metrics for the portfolios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Anlysis\n",
    "\n",
    "#### Calculate and Plot the daily returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:220\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     result \u001b[39m=\u001b[39m func(left, right)\n\u001b[0;32m    221\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[39mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[39m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[39mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[39mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:131\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     result \u001b[39m=\u001b[39m _evaluate_standard(op, op_str, a, b)\n\u001b[0;32m    133\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'NoneType'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ricefolder\\RICE-VIRT-FIN-PT-08-2023-U-LOLC\\UntitledRepo\\Homework\\04-Pandas\\Instructions\\Starter_Code\\whale_analysis.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Plot daily returns of all portfolios\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m daily_returns_Whale \u001b[39m=\u001b[39m Whales_returns_df\u001b[39m.\u001b[39;49mpct_change()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m daily_returns_Algo \u001b[39m=\u001b[39m Algo_returns_df\u001b[39m.\u001b[39mpct_change()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m daily_returns_Sp500 \u001b[39m=\u001b[39m Sp500_historical_df\u001b[39m.\u001b[39mpct_change()\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:11722\u001b[0m, in \u001b[0;36mNDFrame.pct_change\u001b[1;34m(self, periods, fill_method, limit, freq, **kwargs)\u001b[0m\n\u001b[0;32m  11720\u001b[0m shifted \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mshift(periods\u001b[39m=\u001b[39mperiods, freq\u001b[39m=\u001b[39mfreq, axis\u001b[39m=\u001b[39maxis, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m  11721\u001b[0m \u001b[39m# Unsupported left operand type for / (\"Self\")\u001b[39;00m\n\u001b[1;32m> 11722\u001b[0m rs \u001b[39m=\u001b[39m data \u001b[39m/\u001b[39;49m shifted \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m  \u001b[39m# type: ignore[operator]\u001b[39;00m\n\u001b[0;32m  11723\u001b[0m \u001b[39mif\u001b[39;00m freq \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m  11724\u001b[0m     \u001b[39m# Shift method is implemented differently when freq is not None\u001b[39;00m\n\u001b[0;32m  11725\u001b[0m     \u001b[39m# We want to restore the original index\u001b[39;00m\n\u001b[0;32m  11726\u001b[0m     rs \u001b[39m=\u001b[39m rs\u001b[39m.\u001b[39mloc[\u001b[39m~\u001b[39mrs\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mduplicated()]\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:210\u001b[0m, in \u001b[0;36mOpsMixin.__truediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__truediv__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__truediv__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 210\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_arith_method(other, operator\u001b[39m.\u001b[39;49mtruediv)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:7647\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   7644\u001b[0m \u001b[39mself\u001b[39m, other \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_align_for_op(other, axis, flex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, level\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   7646\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 7647\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch_frame_op(other, op, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   7648\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:7690\u001b[0m, in \u001b[0;36mDataFrame._dispatch_frame_op\u001b[1;34m(self, right, func, axis)\u001b[0m\n\u001b[0;32m   7684\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mequals(right\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m   7685\u001b[0m     \u001b[39m# TODO: The previous assertion `assert right._indexed_same(self)`\u001b[39;00m\n\u001b[0;32m   7686\u001b[0m     \u001b[39m#  fails in cases with empty columns reached via\u001b[39;00m\n\u001b[0;32m   7687\u001b[0m     \u001b[39m#  _frame_arith_method_with_reindex\u001b[39;00m\n\u001b[0;32m   7688\u001b[0m \n\u001b[0;32m   7689\u001b[0m     \u001b[39m# TODO operate_blockwise expects a manager of the same type\u001b[39;00m\n\u001b[1;32m-> 7690\u001b[0m     bm \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49moperate_blockwise(\n\u001b[0;32m   7691\u001b[0m         \u001b[39m# error: Argument 1 to \"operate_blockwise\" of \"ArrayManager\" has\u001b[39;49;00m\n\u001b[0;32m   7692\u001b[0m         \u001b[39m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   7693\u001b[0m         \u001b[39m# \"ArrayManager\"\u001b[39;49;00m\n\u001b[0;32m   7694\u001b[0m         \u001b[39m# error: Argument 1 to \"operate_blockwise\" of \"BlockManager\" has\u001b[39;49;00m\n\u001b[0;32m   7695\u001b[0m         \u001b[39m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;49;00m\n\u001b[0;32m   7696\u001b[0m         \u001b[39m# \"BlockManager\"\u001b[39;49;00m\n\u001b[0;32m   7697\u001b[0m         right\u001b[39m.\u001b[39;49m_mgr,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   7698\u001b[0m         array_op,\n\u001b[0;32m   7699\u001b[0m     )\n\u001b[0;32m   7700\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_from_mgr(bm, axes\u001b[39m=\u001b[39mbm\u001b[39m.\u001b[39maxes)\n\u001b[0;32m   7702\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(right, Series) \u001b[39mand\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   7703\u001b[0m     \u001b[39m# axis=1 means we want to operate row-by-row\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1470\u001b[0m, in \u001b[0;36mBlockManager.operate_blockwise\u001b[1;34m(self, other, array_op)\u001b[0m\n\u001b[0;32m   1466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moperate_blockwise\u001b[39m(\u001b[39mself\u001b[39m, other: BlockManager, array_op) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BlockManager:\n\u001b[0;32m   1467\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1468\u001b[0m \u001b[39m    Apply array_op blockwise with another (aligned) BlockManager.\u001b[39;00m\n\u001b[0;32m   1469\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1470\u001b[0m     \u001b[39mreturn\u001b[39;00m operate_blockwise(\u001b[39mself\u001b[39;49m, other, array_op)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\ops.py:65\u001b[0m, in \u001b[0;36moperate_blockwise\u001b[1;34m(left, right, array_op)\u001b[0m\n\u001b[0;32m     63\u001b[0m res_blks: \u001b[39mlist\u001b[39m[Block] \u001b[39m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m lvals, rvals, locs, left_ea, right_ea, rblk \u001b[39min\u001b[39;00m _iter_block_pairs(left, right):\n\u001b[1;32m---> 65\u001b[0m     res_values \u001b[39m=\u001b[39m array_op(lvals, rvals)\n\u001b[0;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m     67\u001b[0m         left_ea\n\u001b[0;32m     68\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m right_ea\n\u001b[0;32m     69\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(res_values, \u001b[39m\"\u001b[39m\u001b[39mreshape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_1d_only_ea_dtype(res_values\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m     71\u001b[0m     ):\n\u001b[0;32m     72\u001b[0m         res_values \u001b[39m=\u001b[39m res_values\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:285\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    281\u001b[0m     _bool_arith_check(op, left, right)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    283\u001b[0m     \u001b[39m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     \u001b[39m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[39mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:229\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    222\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_cmp \u001b[39mand\u001b[39;00m (\n\u001b[0;32m    223\u001b[0m         left\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mgetattr\u001b[39m(right, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m\n\u001b[0;32m    224\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    228\u001b[0m         \u001b[39m#  incorrectly, see GH#32047\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m         result \u001b[39m=\u001b[39m _masked_arith_op(left, right, op)\n\u001b[0;32m    230\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mrjwi\\Anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:165\u001b[0m, in \u001b[0;36m_masked_arith_op\u001b[1;34m(x, y, op)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# See GH#5284, GH#5035, GH#19448 for historical reference\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m--> 165\u001b[0m         result[mask] \u001b[39m=\u001b[39m op(xrav[mask], yrav[mask])\n\u001b[0;32m    167\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_scalar(y):\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "# Plot daily returns of all portfolios\n",
    "daily_returns_Whale = Whales_returns_df.pct_change()\n",
    "daily_returns_Algo = Algo_returns_df.pct_change()\n",
    "daily_returns_Sp500 = Sp500_historical_df.pct_change()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate and Plot cumulative returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'daily_returns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ricefolder\\RICE-VIRT-FIN-PT-08-2023-U-LOLC\\UntitledRepo\\Homework\\04-Pandas\\Instructions\\Starter_Code\\whale_analysis.ipynb Cell 26\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calculate cumulative returns of all portfolios\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m calumative_returns \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m daily_returns)\u001b[39m.\u001b[39mcumprod() \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Plot cumulative returns\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cumulative_returns\u001b[39m.\u001b[39mplot(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m5\u001b[39m), title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCumulative Returns \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'daily_returns' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate cumulative returns of all portfolios\n",
    "calumative_returns = (1 + daily_returns).cumprod() - 1\n",
    "# Plot cumulative returns\n",
    "cumulative_returns.plot(figsize=(10,5), title=\"Cumulative Returns \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Analysis\n",
    "\n",
    "Determine the _risk_ of each portfolio:\n",
    "\n",
    "1. Create a box plot for each portfolio. \n",
    "2. Calculate the standard deviation for all portfolios\n",
    "4. Determine which portfolios are riskier than the S&P 500\n",
    "5. Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a box plot for each portfolio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot to visually show risk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Standard Deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily standard deviations of all portfolios\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine which portfolios are riskier than the S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate  the daily standard deviation of S&P 500\n",
    "\n",
    "# Determine which portfolios are riskier than the S&P 500\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized standard deviation (252 trading days)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics\n",
    "\n",
    "Risk changes over time. Analyze the rolling statistics for Risk and Beta. \n",
    "\n",
    "1. Calculate and plot the rolling standard deviation for all portfolios using a 21-day window\n",
    "2. Calculate the correlation between each stock to determine which portfolios may mimick the S&P 500\n",
    "3. Choose one portfolio, then calculate and plot the 60-day rolling beta between it and the S&P 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot rolling `std` for all portfolios with 21-day window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'daily_returns_Whale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ricefolder\\RICE-VIRT-FIN-PT-08-2023-U-LOLC\\UntitledRepo\\Homework\\04-Pandas\\Instructions\\Starter_Code\\whale_analysis.ipynb Cell 40\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X54sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calculate the rolling standard deviation for all portfolios using a 21-day window\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Whale_sma_21 \u001b[39m=\u001b[39m daily_returns_Whale\u001b[39m.\u001b[39mrolling(window\u001b[39m=\u001b[39m\u001b[39m21\u001b[39m)\u001b[39m.\u001b[39mmean()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X54sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m Algo_sma_21 \u001b[39m=\u001b[39m daily_returns_Algo\u001b[39m.\u001b[39mrolling(window\u001b[39m=\u001b[39m\u001b[39m21\u001b[39m)\u001b[39m.\u001b[39mmean()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#X54sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m Sp500_sma_21 \u001b[39m=\u001b[39m daily_returns_Sp500\u001b[39m.\u001b[39mrolling(window\u001b[39m=\u001b[39m\u001b[39m21\u001b[39m)\u001b[39m.\u001b[39mmean()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'daily_returns_Whale' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the rolling standard deviation for all portfolios using a 21-day window\n",
    "Whale_sma_21 = daily_returns_Whale.rolling(window=21).mean()\n",
    "Algo_sma_21 = daily_returns_Algo.rolling(window=21).mean()\n",
    "Sp500_sma_21 = daily_returns_Sp500.rolling(window=21).mean()\n",
    "# Plot the rolling standard deviation\n",
    "ax =calumative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation\n",
    "\n",
    "# Display de correlation matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and Plot Beta for a chosen portfolio and the S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance of a single portfolio\n",
    "Algo_covarience = daily_returns_Sp500['ALGO'].cov(daily_returns['ALGO'])\n",
    "# Calculate variance of S&P 500\n",
    "variance = daily_returns['SP500']\n",
    "# Computing beta\n",
    "Algo_beta = Algo_covarience / variance\n",
    "# Plot beta trend\n",
    "print(f\"Algo: {Algo_beta}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Statistics Challenge: Exponentially Weighted Average \n",
    "\n",
    "An alternative way to calculate a rolling window is to take the exponentially weighted moving average. This is like a moving window average, but it assigns greater importance to more recent observations. Try calculating the [`ewm`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html) with a 21-day half life for each portfolio, using standard deviation (`std`) as the metric of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `ewm` to calculate the rolling window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpe Ratios\n",
    "In reality, investment managers and thier institutional investors look at the ratio of return-to-risk, and not just returns alone. After all, if you could invest in one of two portfolios, and each offered the same 10% return, yet one offered lower risk, you'd take that one, right?\n",
    "\n",
    "### Using the daily returns, calculate and visualize the Sharpe ratios using a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annualized Sharpe Ratios\n",
    "sharpe_ratios = (all_returns.mean() * 252) / (all_portfolio_std * np.sqrt(252))\n",
    "sharpe_ratios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n",
    "sharpe_ratios.plot.bar(title=\"sharpe Ratios\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine whether the algorithmic strategies outperform both the market (S&P 500) and the whales portfolios.\n",
    "\n",
    "Write your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Custom Portfolio\n",
    "\n",
    "In this section, you will build your own portfolio of stocks, calculate the returns, and compare the results to the Whale Portfolios and the S&P 500. \n",
    "\n",
    "1. Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock.\n",
    "2. Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock\n",
    "3. Join your portfolio returns to the DataFrame that contains all of the portfolio returns\n",
    "4. Re-run the performance and risk analysis with your portfolio to see how it compares to the others\n",
    "5. Include correlation analysis to determine which stocks (if any) are correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose 3-5 custom stocks with at last 1 year's worth of historic prices and create a DataFrame of the closing prices and dates for each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from 1st stock\n",
    "Appl_df = pd.read_csv('Resources\\\\aapl_historical.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from 2nd stock\n",
    "Bros_df = pd.read_csv('Resources\\\\BROS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from 3rd stock\n",
    "Pltr_df = pd.read_csv('Resources\\\\PLTR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ricefolder\\RICE-VIRT-FIN-PT-08-2023-U-LOLC\\UntitledRepo\\Homework\\04-Pandas\\Instructions\\Starter_Code\\whale_analysis.ipynb Cell 58\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#Y111sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Combine all stocks in a single DataFrame\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#Y111sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m combined_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([Appl_df, Bros_df, Pltr_df], axis\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m, join\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Combine all stocks in a single DataFrame\n",
    "combined_df = pd.concat([Appl_df, Bros_df, Pltr_df], axis=\"columns\", join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Ricefolder\\RICE-VIRT-FIN-PT-08-2023-U-LOLC\\UntitledRepo\\Homework\\04-Pandas\\Instructions\\Starter_Code\\whale_analysis.ipynb Cell 59\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Reset Date index\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Ricefolder/RICE-VIRT-FIN-PT-08-2023-U-LOLC/UntitledRepo/Homework/04-Pandas/Instructions/Starter_Code/whale_analysis.ipynb#Y112sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df_reset \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mreset_index()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Reset Date index\n",
    "df_reset = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize portfolio data by having a column per symbol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "\n",
    "# Drop NAs\n",
    "\n",
    "# Display sample data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the weighted returns for the portfolio assuming an equal number of shares for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set weights\n",
    "weights = [1/3, 1/3, 1/3]\n",
    "\n",
    "# Calculate portfolio return\n",
    "\n",
    "# Display sample data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join your portfolio returns to the DataFrame that contains all of the portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join your returns DataFrame to the original returns DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only compare dates where return data exists for all the stocks (drop NaNs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run the risk analysis with your portfolio to see how it compares to the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Annualized Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the annualized `std`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot rolling `std` with 21-day window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling standard deviation\n",
    "\n",
    "# Plot rolling standard deviation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and plot the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot the correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and Plot Rolling 60-day Beta for Your Portfolio compared to the S&P 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot Beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the daily returns, calculate and visualize the Sharpe ratios using a bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Annualized Sharpe Ratios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sharpe ratios as a bar plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does your portfolio do?\n",
    "\n",
    "Write your answer here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
